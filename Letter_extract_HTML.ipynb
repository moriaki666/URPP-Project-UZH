{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca938360-aa40-4c39-b3cb-7f7279ddbd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title:\n",
      "Bitte um materielle Unterstützung bei Renovierungsarbeiten am Kloster (Lüneburg, Kloster Lüne, Hs. 15, Lage 4, fol. 2v, Brief 30) - Transkription\n",
      "\n",
      "Contributors:\n",
      "- Herausgegeben von Eva Schlotheuber (Heinrich-Heine-Universität Düsseldorf)\n",
      "- Herausgegeben von Henrike Lähnemann (Universität Oxford)\n",
      "- Bearbeitet von Simone Schultz-Balluff (Universität Bonn)\n",
      "- Bearbeitet von Edmund Wareham (Universität Oxford)\n",
      "- Bearbeitet von Philipp Trettin (Heinrich-Heine-Universität Düsseldorf)\n",
      "- unter Mitarbeit von Philipp Stenzig (Heinrich-Heine-Universität Düsseldorf)\n",
      "- unter Mitarbeit von Timo Bülters ( Universität Bonn)\n",
      "- unter Mitarbeit von Mai-Britt Wiechmann (Universität Oxford)\n",
      "- digitale Umsetzung Wolfgang Seifert (Herzog August Bibliothek Wolfenbüttel)\n",
      "\n",
      "Description (DE):\n",
      "Die Absenderin erinnert ihren Onkel an sein Versprechen, sich in Mangelsituationen an ihn wenden zu können. Sie verweist auf Renovierungsarbeiten am Kloster, für die sie Holz benötigen. Der Empfänger möge die drei Onkel der Absenderin, Thomas Badeken, H. Monnickhußen und Georgius von Gilten, grüßen. Letzterem soll ausgerichtet werden, dass Gertrud von Gilten am vergangenen Sonntag Letare ihre Professfeier abgehalten hat und am Sonntag Jubilate gekrönt wurde.\n",
      "\n",
      "Description (EN):\n",
      "The Lüne nun reminds her uncle of his promise that she can turn to him in times of need. She writes that renovation works will be carried out in the convent if there is sufficient wood. She asks him to greet her uncles Thomas Ludeke, H. Monnickhusen and Georg von Ghilten. She writes that Gertrud von Ghilten celebrated her solemn profession on the Fourth Sunday in Lent and was crowned on the Third Sunday after Easter. This letter must date from before 1481 because Gertrud celebrated both solemn profession and coronation in quick succession in the same year, which was forbidden by the conventual reforms of 1481, and her name is not mentioned in the convent’s chronicle which only began in that year.\n",
      "\n",
      "Document Details:\n",
      "Nonne im Kloster Lüne an ihren Onkel\n",
      "vor Oktober 1481\n",
      "Bitte um materielle Unterstützung bei Renovierungsarbeiten am Kloster — Request for material support for renovation works in the convent\n",
      "\n",
      "Manuscript Details:\n",
      "Kloster Lüne, Hs. 15, Lage 4, fol. 2v\n",
      "\n",
      "Transcription:\n",
      "1 Orationes o si devotas cum affectum innate\n",
      "2 karitatis in eo qui dicit  Petite et accipietis\n",
      "1\n",
      "3 reverende domine et religiose pater ymmoque\n",
      "[\n",
      "Lage 4, fol. 3r\n",
      "]\n",
      "4 avuncule in Domino Jesu michi preamande.   Me=\n",
      "5 mor benivole vestre sponditionis qua satis\n",
      "6 benigne spopondistis si\n",
      "               umquam  adop=\n",
      "7 tatum mee parvitatis aliqua bona  impende\n",
      "8 re petueritis quam\n",
      "               libenter ageretis\n",
      "9 Quodque promissum ut audivi oretenus\n",
      "10 vos narrare ad me\n",
      "               aliquantis annis\n",
      "11 dum quandam nostra ratione exposcente ad\n",
      "12 fenestram\n",
      "               locutionis nobis loquebamini nunc\n",
      "13 presenti cum immensis gratiarum\n",
      "acti\n",
      "a\n",
      "actionibus\n",
      "14 tam bone voluntatis illius premissi  spondi\n",
      "15 tionis vos admoneo.  humillimeque  flagi=\n",
      "16 tans amore Jesu Christi et consanguinitatis\n",
      "17 quatenus idem facto et\n",
      "               re adimplere  digne=\n",
      "18 mini iam in presenti petitione quam nostra\n",
      "19 congregatio facit ad\n",
      "               vestram reverendam\n",
      "20 paternitatem ob honorem omnipotentis Dei\n",
      "21 cuius gloriam\n",
      "               advertentes intendimus  edifi=\n",
      "[\n",
      "Lage 4, fol. 3v\n",
      "]\n",
      "22 cium nostri monasterii renovare et  reedi\n",
      "23 ficare presertim  aliquos  domos nimis\n",
      "24  labefactus si copia lignorum non deesset\n",
      "25 quodque orationibus quamquam aridis\n",
      "               libenter\n",
      "26 exsolvemus die noctuque.  Consequen\n",
      "27 terque peto humiliter quatenus nostros caros\n",
      "28 avunculos\n",
      "               videlicet dominum Thomam\n",
      "29  Badeken  et H\n",
      "                  Monnickhußen  necnon\n",
      "30 Georgium de Ghilten  dignemini  sa=\n",
      "31 lutare causa nostri de Hůdenberghe\n",
      "2\n",
      "et\n",
      "32 Gertrud de Ghilten\n",
      "3\n",
      "de qua peto ut  ger=\n",
      "33 mano suo iam nominato insinuare\n",
      "34 dignemini  quod ipsa in dominica Letare\n",
      "35 est suscepta ad\n",
      "               professionem et in dominica\n",
      "36 iubilate proxime preterita est coronata\n",
      "4\n",
      "37 Reverende domine utique predilecte  avun=\n",
      "38 cule.  cum hiis paucis commendo vestram\n",
      "39 reverentiam sanam et incolumen\n",
      "                  eidem\n",
      "[\n",
      "Lage 4, fol. 4r\n",
      "]\n",
      "40 clementissimo nostro salvatori qui dignetur\n",
      "41 nobis in suo nomine quoque\n",
      "               salutaria ad\n",
      "42 postulandum gratiam suam infundere  pe=\n",
      "43 titaque salubriter prestare ut post\n",
      "44 modum valeamus eadem\n",
      "               pleno\n",
      "45 gaudio possidere Amen.\n",
      "\n",
      "Critical Apparatus:\n",
      "Kritischer Apparat\n",
      "a\n",
      "hier gestrichen\n",
      "acti\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extract_content(file_path):\n",
    "    # Read the HTML file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "    content = []\n",
    "    \n",
    "    # Extract title\n",
    "    title = soup.find('title')\n",
    "    if title:\n",
    "        content.append((\"Title\", title.text.strip()))\n",
    "    \n",
    "    # Extract contributors\n",
    "    contributors = soup.find_all('meta', attrs={'name': 'dc.contributor'})\n",
    "    if contributors:\n",
    "        content.append((\"Contributors\", [c['content'] for c in contributors]))\n",
    "    \n",
    "    # Extract descriptions\n",
    "    desc_de = soup.find('meta', attrs={'name': 'description', 'lang': 'de'})\n",
    "    desc_en = soup.find('meta', attrs={'name': 'description', 'lang': 'en'})\n",
    "    if desc_de:\n",
    "        content.append((\"Description (DE)\", desc_de['content']))\n",
    "    if desc_en:\n",
    "        content.append((\"Description (EN)\", desc_en['content']))\n",
    "    \n",
    "    # Extract document details\n",
    "    head = soup.find('div', class_='head')\n",
    "    if head:\n",
    "        content.append((\"Document Details\", head.get_text(strip=True, separator='\\n')))\n",
    "    \n",
    "    # Extract manuscript details\n",
    "    ms_details = soup.find('p', class_='msIdentifier')\n",
    "    if ms_details:\n",
    "        content.append((\"Manuscript Details\", ms_details.text.strip()))\n",
    "    \n",
    "    # Extract transcription\n",
    "    transcript = soup.find('div', class_='transcript')\n",
    "    if transcript:\n",
    "        content.append((\"Transcription\", transcript.get_text(strip=True, separator='\\n')))\n",
    "    \n",
    "    # Extract critical apparatus\n",
    "    crit_app = soup.find('div', class_='critApp')\n",
    "    if crit_app:\n",
    "        content.append((\"Critical Apparatus\", crit_app.get_text(strip=True, separator='\\n')))\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Specify the path to your HTML file\n",
    "#file_path = '/Users/manaswimondol/Downloads/letter_transcripts/content.php-dir=edoc|ed000248&distype=optional&metsID=edoc_ed000248_lg-kl-hs15-01-01r-001-D_tei-transcript&xml=texts|Brief001-D_tei-transcript.xml&xsl=scripts|tei-transcript.xsl&view=diplomatic.html'\n",
    "file_path = '/Users/manaswimondol/Downloads/letter_transcripts/content.php-dir=edoc|ed000248&distype=optional&metsID=edoc_ed000248_lg-kl-hs15-04-02v-030-L_tei-transcript&xml=texts|Brief030-L_tei-transcript.xml&xsl=scripts|tei-transcript.xsl&view=diplomatic.html'\n",
    "# Extract the content\n",
    "extracted_content = extract_content(file_path)\n",
    "\n",
    "# Print the extracted content\n",
    "for heading, text in extracted_content:\n",
    "    print(f\"\\n{heading}:\")\n",
    "    if isinstance(text, list):\n",
    "        for item in text:\n",
    "            print(f\"- {item}\")\n",
    "    else:\n",
    "        print(text)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06160b-baa9-47c5-8a3d-8b025d4f1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_content(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "    content = {\n",
    "        'File': os.path.basename(file_path),\n",
    "        'Title': '',\n",
    "        'Contributors': '',\n",
    "        'Description (DE)': '',\n",
    "        'Description (EN)': '',\n",
    "        'Document Details': '',\n",
    "        'Manuscript Details': '',\n",
    "        'Transcription': '',\n",
    "        'Critical Apparatus': ''\n",
    "    }\n",
    "    \n",
    "    title = soup.find('title')\n",
    "    if title:\n",
    "        content['Title'] = title.text.strip()\n",
    "    \n",
    "    contributors = soup.find_all('meta', attrs={'name': 'dc.contributor'})\n",
    "    if contributors:\n",
    "        content['Contributors'] = '; '.join([c['content'] for c in contributors])\n",
    "    \n",
    "    desc_de = soup.find('meta', attrs={'name': 'description', 'lang': 'de'})\n",
    "    if desc_de:\n",
    "        content['Description (DE)'] = desc_de['content']\n",
    "    \n",
    "    desc_en = soup.find('meta', attrs={'name': 'description', 'lang': 'en'})\n",
    "    if desc_en:\n",
    "        content['Description (EN)'] = desc_en['content']\n",
    "    \n",
    "    head = soup.find('div', class_='head')\n",
    "    if head:\n",
    "        content['Document Details'] = head.get_text(strip=True, separator=' ')\n",
    "    \n",
    "    ms_details = soup.find('p', class_='msIdentifier')\n",
    "    if ms_details:\n",
    "        content['Manuscript Details'] = ms_details.text.strip()\n",
    "    \n",
    "    transcript = soup.find('div', class_='transcript')\n",
    "    if transcript:\n",
    "        content['Transcription'] = transcript.get_text(strip=True, separator=' ')\n",
    "    \n",
    "    crit_app = soup.find('div', class_='critApp')\n",
    "    if crit_app:\n",
    "        content['Critical Apparatus'] = crit_app.get_text(strip=True, separator=' ')\n",
    "    \n",
    "    return content\n",
    "\n",
    "def process_directory(directory_path, output_file):\n",
    "    all_content = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.html'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            content = extract_content(file_path)\n",
    "            all_content.append(content)\n",
    "    \n",
    "    df = pd.DataFrame(all_content)\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "# Specify the directory containing your HTML files\n",
    "directory_path = '/Users/manaswimondol/Downloads/Letters_content'\n",
    "\n",
    "# Specify the output CSV file path\n",
    "output_file = 'extracted_content.csv'\n",
    "\n",
    "# Process all HTML files in the directory and save the results\n",
    "process_directory(directory_path, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
